#!/usr/bin/env bash
# coded by CyberZest
# inspired by Asheem Shrey
# Vasuki - version 1.0

#@> CHECK CONNECTION
wget -q --spider http://google.com
if [ $? -ne 0 ];then
    echo "Connect to internet before running Vasuki!"
    exit 127
fi

#### COLORS #### ( Taken from : https://misc.flogisoft.com/bash/tip_colors_and_formatting )
BK="\e[38;5;166m" #Blink
GR="\e[32m"
YW="\e[93m"
NORMAL='\e[0m'
RED='\e[31m'
LIGHT_GREEN='\e[92m'
LIGHT_YELLOW='\e[93m'
MAGENTA='\e[35m'
LIGHT_MAGENTA='\e[96m'
LIGHT_GREY='\e[90m'
BOLD='\e[1m'
UNDERLINE='\e[4m'
#############################################

#@> VARIABLES
DM=
EC=
RF=
SL=False
JO=False
RO=False
VR="Vasuki v1.0"
PR="21,22,80,81,280,300,443,583,591,593,832,981,1010,1099,1311,2082,2087,2095,2096,2480,3000,3128,3333,4243,4444,4445,4567,4711,4712,4993,5000,5104,5108,5280,5281,5601,5800,6543,7000,7001,7002,7396,7474,8000,8001,8008,8009,8014,8042,8060,8069,8080,8081,8083,8088,8090,8091,8095,8118,8123,8172,8181,8222,8243,8280,8281,8333,8337,8443,8500,8530,8531,8834,8880,8887,8888,8983,9000,9001,9043,9060,9080,9090,9091,9092,9200,9443,9502,9800,9981,10000,10250,10443,11371,12043,12046,12443,15672,16080,17778,18091,18092,20720,28017,32000,55440,55672"


#@> PRINT USAGE
PRINT_USAGE(){
    echo -e ""
    echo -e "${LIGHT_YELLOW}
\t\t██╗░░░██╗░█████╗░░██████╗██╗░░░██╗██╗░░██╗██╗
\t\t██║░░░██║██╔══██╗██╔════╝██║░░░██║██║░██╔╝██║
\t\t╚██╗░██╔╝███████║╚█████╗░██║░░░██║█████═╝░██║
\t\t░╚████╔╝░██╔══██║░╚═══██╗██║░░░██║██╔═██╗░██║
\t\t░░╚██╔╝░░██║░░██║██████╔╝╚██████╔╝██║░╚██╗██║
\t\t░░░╚═╝░░░╚═╝░░╚═╝╚═════╝░░╚═════╝░╚═╝░░╚═╝╚═╝
${NORMAL}"
    echo -e "[${YW}VASUKI${NORMAL}] == A Reconnaissance Suite for BUG-HUNTERS (${BOLD}${MAGENTA}@CyberZest${NORMAL})"
    echo -e ""
    echo -e "Example Usage:"
    echo -e "vasuki [-d target.tld] [-x exclude domains] [-r resolvers] [-rF resolvers list] [--json] [-s]"
    echo -e ""
    echo -e "Flags:"
    echo -e "   -d, --domain             ${BK}string${NORMAL}       Add your target                         -d target.tld"
    echo -e "   -x, --exclude            ${BK}string${NORMAL}       Exclude out of scope domains            -x ~/dommains.list"
    echo -e "   -r, --resolver           ${BK}string${NORMAL}       Resolver Name                           -r 8.8.8.8, 8.8.4.4, 10.10.10.10"
    echo -e "   -rF, --resolvers         ${BK}string${NORMAL}       Resolver File List                      -rF ~/resolver.txt"
    echo -e ""
    echo -e "${BOLD}${LIGHT_MAGENTA}Optional Flags: ${NORMAL}"
    echo -e "   -s, --silent      Hide output in the terminal             ${GR}Default: ${BOLD}${LIGHT_MAGENTA}False${NORMAL}"
    echo -e "   -j, --json        Store output in a single json file      ${GR}Default: ${BOLD}${LIGHT_MAGENTA}False${NORMAL}"
    echo -e "   -v, --version     Print current version of vasuki"
    exit 0
}

#@> ARGUMENTS
while [ -n "$1" ]; do
    case $1 in
            -d|--domain)
                DM=$2
                shift ;;

            -rF|--resolvers)
                RF=$2
                shift ;;

            -h|--help)
                PRINT_USAGE
                shift ;;

            -j|--json)
                JO='true'
                ;;

            -s|--silent)
                SL='true'
                ;;

            -x|--exclude)
                EC=$2
                shift ;;

            -v|--version)
                echo -e "$VR"
                exit 0 ;;

            *)
                PRINT_USAGE
    esac
    shift
done


#@> INITIAL CONFIGS
if [ -z "$DM" ]; then
    echo -e "\n${BOLD}${LIGHT_MAGENTA}ERROR${NORMAL} - TARGET NOT SUPPLIED."
    PRINT_USAGE
fi

if [ "$RO" == "true" ]; then
    JO='true'
fi

#@> DOCKER
if [ -z "$CHROME_BIN" ]; then
    CHROME_BIN="/snap/bin/chromium"
fi

#@> EXIT FUNCTION
trap ctrl_c INT
ctrl_c(){
    echo -e ""
    echo -e "${YW} [!] ${NORMAL} KEYBOARD INTERRUPTION, ${RED}EXITING VASUKI${NORMAL}..."
    exit 127
}

#@> BANNER
INFOM(){
    clear
    echo -e ""
    echo -e "${YW}
\t\t██╗░░░██╗░█████╗░░██████╗██╗░░░██╗██╗░░██╗██╗
\t\t██║░░░██║██╔══██╗██╔════╝██║░░░██║██║░██╔╝██║
\t\t╚██╗░██╔╝███████║╚█████╗░██║░░░██║█████═╝░██║
\t\t░╚████╔╝░██╔══██║░╚═══██╗██║░░░██║██╔═██╗░██║
\t\t░░╚██╔╝░░██║░░██║██████╔╝╚██████╔╝██║░╚██╗██║
\t\t░░░╚═╝░░░╚═╝░░╚═╝╚═════╝░░╚═════╝░╚═╝░░╚═╝╚═╝
${NORMAL}"
    echo -e "[${YW}VASUKI${NORMAL}] == A Reconnaissance Suite for BUG-HUNTERS (${BOLD}${MAGENTA}@CyberZest${NORMAL})"
    dt=$(date +%F.%H.%M)
    resultDir=~/vasuki_results/$DM/$dt
    echo -e $resultDir
    mkdir -p $resultDir
    cd $resultDir
    ReconStartTime=$(date +%H.%M.%S)
    echo -e ""
    echo -e "${BOLD}${LIGHT_MAGENTA}DOMAIN> ${NORMAL}" | tr -d "\n"; echo -e " $DM" | pv -qL 6
    echo -e "${BOLD}${LIGHT_MAGENTA}OUTPUT> ${NORMAL}" | tr -d "\n"; echo -e " $(pwd | sed 's/\// < /g' | cut -c 4-)" | pv -qL 6
    echo -e "[VASUKI] - Scanning started on $DM at $ReconStartTime" | notify -silent
}

#@> MAKE FOLDERS
MAKDR(){
    echo -e "Results in : ${BOLD}$resultDir${NORMAL}"
    mkdir -p $resultDir/tmp
    mkdir -p $resultDir/.gf
    mkdir -p $resultDir/dirs
    mkdir -p $resultDir/vulns
    mkdir -p $resultDir/nmap
    [ "$JO" == "False" ] || mkdir -p $resultDir/.json
}

#@> SUBDOMAIN ENUMERATION
SUBD_PASV(){
    curl -s "https://crt.sh/?q=%25.$DM&output=json" | jq -r '.[].name_value' 2>/dev/null | sed 's/\*\.//g' | sort -u | grep -o "\w.*$DM" | anew -q $resultDir/tmp/cert.list
    curl -s "https://api.hackertarget.com/hostsearch/?q=$DM" | grep -o "\w.*$DM" | anew -q $resultDir/tmp/htarget.list
    curl -s "https://riddler.io/search/exportcsv?q=pld:$DM" | grep -Po "(([\w.-]*)\.([\w]*)\.([A-z]))\w+" | grep -o "\w.*$DM" | anew -q $resultDir/tmp/riddler.list
    amass enum -passive -d $DM -rf $RF -o $resultDir/tmp/amass.list &> /dev/null
    assetfinder --subs-only $DM | anew -q $resultDir/tmp/assetfinder.list &> /dev/null
    subfinder -silent -d $DM -rL $RF -all -t 100 -o $resultDir/tmp/subfinder.list &> /dev/null
    findomain -t $DM --threads 40 -u $resultDir/tmp/findomain.list &> /dev/null
}

#SUBD_ACTV(){
#   timeout 50m ffuf -u http://FUZZ.$DM/ -t 100 -p '1.0-2.0' -w $RF -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36" -mc 200 -r -o $resultDir/tmp/ffuf.json -s 2> /dev/null &> /dev/null
#    timeout 50m gobuster dns -d $DM --no-error -z -q -t 100 -w $RF 2> /dev/null | sed 's/Found: //g' | anew -q $resultDir/tmp/gobuster.list
#    timeout 50m amass enum -active -brute -w ~/vasuki/wordlists/subdomains.txt -d $DM -rf $RF -o $resultDir/tmp/amassact.list &> /dev/null
#    cat $resultDir/tmp/ffuf.json 2> /dev/null | jq -r '.results[] | .host' 2> /dev/null | anew -q $resultDir/tmp/ffuf.list && rm -rf $resultDir/tmp/ffuf.json
#}


SUBD_SCND(){
    cat $resultDir/tmp/*.list | grep -v "*" | sed '/@\|<BR>\|\_\|*/d' | grep "$DM" | anew -q tmp/domains
    xargs -a $resultDir/tmp/domains -P 50 -I % bash -c "assetfinder --subs-only % | anew -q $resultDir/tmp/seconddomains.list" 2> /dev/null | anew -q $resultDir/tmp/seconddomains.list
}
    
    
SUBD_CHCK(){
    #@> FILTERING DOMAINS    
    if [ -f "$EC" ]; then
        cat tmp/domains | grep -vf $EC | dnsx -a -aaaa -cname -ns -ptr -mx -soa -retry 3 -r $RF -t 10 -silent | anew -q $resultDir/subdomains.txt
    else
        cat tmp/domains | dnsx -a -aaaa -cname -ns -ptr -mx -soa -retry 3 -r $RF -t 10 -silent | anew -q $resultDir/subdomains.txt
    fi

    #@> WEB PROBING AND SCREENSHOT
    naabu -retries 3 -r $RF -l $resultDir/subdomains.txt -p "$PR" -silent -no-color 2> /dev/null | anew -q $resultDir/ports.txt
    cat $resultDir/ports.txt | httprobe -prefer-https | anew -q $resultDir/lives.txt
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "echo % | aquatone -chrome-path $CHROME_BIN -out $resultDir/screenshots/ -threads 10 -silent" 2> /dev/null &> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/lives.txt | python3 -c "import sys; import json; print (json.dumps({'liveurls':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/liveurls.json &> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/subdomains.txt | python3 -c "import sys; import json; print (json.dumps({'subdomains':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/subdomains.json &> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/ports.txt | python3 -c "import sys; import json; print (json.dumps({'ports':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/ports.json &> /dev/null
}

SUBD_SCAN(){
    echo -e ""
    echo -e "${BOLD}${LIGHT_MAGENTA}        ${NORMAL}" | tr -d '\n' | pv -qL 4; echo -e " STARTING SUBDOMAIN SCANNING ON ${BOLD}${LIGHT_MAGENTA}$DM${NORMAL} (${YW}it may take time${NORMAL})"
    SUBD_PASV
#   SUBD_ACTV
    SUBD_SCND
    SUBD_CHCK
    [ "$SL" == "False" ] && cat $resultDir/lives.txt 2> /dev/null
    echo -e "Subdomain enumeration completed, total [Subdomains:$(cat $resultDir/subdomains.txt | wc -l)  Activeurls:$(cat $resultDir/lives.txt | wc -l)] found" | notify -silent &> /dev/null
}

#@> IP SCAN AND FILTERING
find_ips(){
    echo -e "${LIGHT_YELLOW}Now doing massdns on the domain${NORMAL}"
  # Do masscanning only when massdns is finished working
#    massdnsOutput=$resultDir/$DM.ips.txt
#    allSubdomainsOutput=$resultDir/subdomains.txt
    massdnstemp=$DM.massdns.tmp
    massdns -r $RF -t A -o S -w $massdnstemp $resultDir/subdomains.txt | tee -a $resultDir/massdns-log.txt
    # resolved domain names
    # cat $massdnstemp | cut -f1 -d" " | sed -e "s/\.$//g" | sort -u 
    cat $massdnstemp | cut -d" " -f3 | grep -oE "\b([0-9]{1,3}\.){3}[0-9]{1,3}\b" >> $resultDir/$DM.ips.txt
    rm $massdnstemp
    echo -e "${LIGHT_GREEN}Massdns complete${NORMAL}"
    #################   MASSDNS COMPLETE  ################################# 
}

find_ipclean(){
    echo -e "${LIGHT_YELLOW}Cleaning ip for masscan, obtained from massdns${NORMAL}"
#    ipfile=$resultDir/$DM.massdns_clean_ip.txt
    python3 ~/vasuki/clean-ip.py $resultDir/$DM.ips.txt $resultDir/$DM.massdns_clean_ip.txt
}

MASSCAN_IP(){
################################ MASSCAN ####################################
    echo -e "${LIGHT_YELLOW}Now doing masscan on all the obtained ip addreses from massdns${NORMAL}"
#    masscanOutput=$resultDir/$DM.masscan.txt
    masscan -iL $resultDir/$DM.massdns_clean_ip.txt -p1-65535 --rate=10000 > $resultDir/$DM.masscan.txt    
    sed -i -e "/#/d " -e "/^$/* " $resultDir/$DM.masscan.txt
    cut -d" " -f4,6 $resultDir/$DM.masscan.txt | awk '{print($2","$1)}' | sort -V > $resultDir/$DM.masscan-sorted.txt
    echo -e "${BOLD}${LIGHT_GREEN}Total unique IP-Ports found : `wc -l $resultDir/$DM.masscan-sorted.txt`${NORMAL}"
    echo -e "${LIGHT_GREEN}Masscan complete${NORMAL}"
#####################   MASSCAN COMPLETE  ####################################   	
  	
#####################   NMAP SORTED FILE PYTHON  ############################
#   nmapFile1=$resultDir/$DM.nmap-sorted.txt
    nmapFile2=$resultDir/$DM.nmap-feedable.txt
    echo -e "${LIGHT_YELLOW}Sorting ${LIGHT_YELLOW}$resultDir/$DM.masscan-sorted.txt for creating nmap suitable file${NORMAL}"     
    sort -k1 $resultDir/$DM.masscan-sorted.txt | awk -F, '{printf $1" "; print $2}' | awk '{if (a!=$1) {if (a) print ""}; printf $0","; a=$1}' | sed 's/,$//' > $resultDir/$DM.nmap-sorted.txt
    tr -d '/tcp' < $resultDir/$DM.nmap-sorted.txt > $nmapFile2
    rm $resultDir/$DM.nmap-sorted.txt 
#####################   NMAP SORTED FILE PYTHON COMPLETE  ###################

#####################   NMAP  ###############################################
#     nmapOutput=$resultDir/nmap/$DM.nmap
}

nmap_run(){
    filePath=$nmapFile2

    if [ ! -f $filePath ]
    then
        echo "Error: Must supply file"
        exit 1
    fi

    while read -r line
    do
        IP=`echo $line | cut -d" " -f1`
        ports=`echo $line | cut -d" " -f2`
        echo "Scanning $IP : $ports : $3"
        nmap -Pn -n -v -A -sV --script=vulscan.nse $IP -p$ports -oA $resultDir/nmap/$IP.vulscan | tee -a $resultDir/nmap/nmap-vulscan-log.txt
        nmap -Pn -n -v -A -sV --script=nmap-vulners/vulners.nse $IP -p$ports -oA $resultDir/nmap/$IP.vulners | tee -a $resultDir/nmap/nmap-vulners-log.txt
    done > $resultDir/$DM.nmap.finished
}

######################   NMAP COMPLETE  ######################################

#@> WEB CRAWLING AND FILTERING
WEBC_RAWL(){
    echo -e "${BOLD}${LIGHT_MAGENTA}        ${NORMAL}" | tr -d '\n' | pv -qL 6; echo -e " STARTING WEBCRAWLING ON ${BOLD}${LIGHT_MAGENTA}$DM${NORMAL} (${YW}it may take time${NORMAL})" | notify -silent &> /dev/null
    timeout 50m gospider -S $resultDir/lives.txt -d 10 -c 20 -t 50 -K 3 --no-redirect --js -a -w --blacklist ".(eot|jpg|jpeg|gif|css|tif|tiff|png|ttf|otf|woff|woff2|ico|svg|txt)" --include-subs -q -o $resultDir/tmp/gospider 2> /dev/null | anew -q $resultDir/tmp/gospider.list
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "echo % | waybackurls" 2> /dev/null | anew -q $resultDir/tmp/waybackurls.list
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "echo % | gau --blacklist eot,jpg,jpeg,gif,css,tif,tiff,png,ttf,otf,woff,woff2,ico,svg,txt --threads 50" 2> /dev/null | anew -q $resultDir/tmp/gau.list 2> /dev/null &> /dev/null
    agnee -d $DM -q -o $resultDir/dorks.txt -p 4 &> /dev/null
    cat $resultDir/tmp/gospider.list $resultDir/tmp/gau.list $resultDir/tmp/waybackurls.list 2> /dev/null | sed '/\[/d' | grep $DM | sort -u | uro | anew -q $resultDir/urls.txt # <-- Filtering duplicate and common endpoints
    [ "$JO" == "False" ] || cat $resultDir/urls.txt | python3 -c "import sys; import json; print (json.dumps({'endpoints':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/urls.json &> /dev/null

    #@> FILTERING ENDPOINTS USING PATTERNS
    gf xss $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "FUZZ" 2> /dev/null | anew -q $resultDir/.gf/xss.list
    gf lfi $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "FUZZ" 2> /dev/null | anew -q $resultDir/.gf/lfi.list
    gf rce $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "FUZZ" 2> /dev/null | anew -q $resultDir/.gf/rce.list
    gf ssrf $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "http://169.254.169.254/latest/meta-data/hostname" 2> /dev/null | anew -q $resultDir/.gf/ssrf.list
    gf ssti $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "FUZZ" 2> /dev/null | anew -q $resultDir/.gf/ssti.list
    gf sqli $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "(select(0)from(select(sleep(5)))v)" 2> /dev/null | anew -q $resultDir/.gf/sqli.list
    gf redirect $resultDir/urls.txt | sed "s/'\|(\|)//g" | bhedak "http://www.evil.com/" 2> /dev/null | anew -q $resultDir/.gf/redirect.list

    xargs -a $resultDir/.gf/xss.list -P 30 -I % bash -c "echo % | kxss" 2> /dev/null | grep "< >\|\"" | awk '{print $2}' | anew -q $resultDir/tmp/xssp.list
    cat $resultDir/tmp/xssp.list 2> /dev/null | bhedak "\">/><svg/onload=confirm(document.domain)>" 2> /dev/null | anew -q $resultDir/tmp/xss.txt
    echo -e "Web Crawling completed, total [URL's:$(cat $resultDir/urls.txt | wc -l)] found" | notify -silent &> /dev/null
}

#@> NUCLEI SCAN
NUCL_SCAN(){
    echo -e "${BOLD}${LIGHT_MAGENTA}        ${NORMAL}" | tr -d '\n' | pv -qL 6; echo -e " STARTING NUCLEI VULNERABILITY SCANNING ON ${BOLD}${LIGHT_MAGENTA}$DM${NORMAL} (${YW}it may take time${NORMAL})" | notify -silent
    nuclei -update-templates 2> /dev/null &> /dev/null
#    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "nuclei -target % -nc -s info" 2> /dev/null | anew -q $resultDir/vulns/nuclei.txt | notify -silent &> /dev/null
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "nuclei -target % -nc -s low" 2> /dev/null | anew $resultDir/vulns/nuclei.txt | notify -silent &> /dev/null
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "nuclei -target % -nc -s medium" 2> /dev/null | anew $resultDir/vulns/nuclei.txt | notify -silent &> /dev/null
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "nuclei -target % -nc -s high" 2> /dev/null | anew $resultDir/vulns/nuclei.txt | notify -silent &> /dev/null
    xargs -a $resultDir/lives.txt -P 50 -I % bash -c "nuclei -target % -nc -s critical" 2> /dev/null | anew $resultDir/vulns/nuclei.txt | notify -silent &> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/nuclei.txt | python3 -c "import sys; import json; print (json.dumps({'nuclei_info':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/nuclei.json &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/nuclei.txt
}

#@> VULNERABILITY SCANNING
VULN_SCAN(){
    echo -e "${BOLD}${LIGHT_MAGENTA}        ${NORMAL}" | tr -d '\n' | pv -qL 6; echo -e " STARTING INJECTION VULNERABILITY SCANNING ON ${BOLD}${LIGHT_MAGENTA}$DM${NORMAL} (${YW}it may take time${NORMAL})" | notify -silent

    crlfuzz -l $resultDir/lives.txt -c 50 -s | anew $resultDir/vulns/crlf.txt | notify -silent &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/crlf.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/crlf.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'vuln_crlf':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/crlf.json &> /dev/null

    cat $resultDir/urls.txt | cut -d"?" -f1 | cut -d"=" -f1 | grep -iaE "([^.]+)\.zip$|([^.]+)\.zip\.[0-9]+$|([^.]+)\.zip[0-9]+$|([^.]+)\.zip[a-z][A-Z][0-9]+$|([^.]+)\.zip\.[a-z][A-Z][0-9]+$|([^.]+)\.rar$|([^.]+)\.tar$|([^.]+)\.tar\.gz$|([^.]+)\.tgz$|([^.]+)\.sql$|([^.]+)\.db$|([^.]+)\.sqlite$|([^.]+)\.pgsql\.txt$|([^.]+)\.mysql\.txt$|([^.]+)\.gz$|([^.]+)\.config$|([^.]+)\.log$|([^.]+)\.bak$|([^.]+)\.backup$|([^.]+)\.bkp$|([^.]+)\.crt$|([^.]+)\.dat$|([^.]+)\.eml$|([^.]+)\.java$|([^.]+)\.lst$|([^.]+)\.key$|([^.]+)\.passwd$|([^.]+)\.pl$|([^.]+)\.pwd$|([^.]+)\.mysql-connect$|([^.]+)\.jar$|([^.]+)\.cfg$|([^.]+)\.dir$|([^.]+)\.orig$|([^.]+)\.bz2$|([^.]+)\.old$|([^.]+)\.vbs$|([^.]+)\.img$|([^.]+)\.inf$|([^.]+)\.sh$|([^.]+)\.py$|([^.]+)\.vbproj$|([^.]+)\.mysql-pconnect$|([^.]+)\.war$|([^.]+)\.go$|([^.]+)\.psql$|([^.]+)\.sql\.gz$|([^.]+)\.vb$|([^.]+)\.webinfo$|([^.]+)\.jnlp$|([^.]+)\.cgi$|([^.]+)\$resultDir/tmp$|([^.]+)\.ini$|([^.]+)\.webproj$|([^.]+)\.xsql$|([^.]+)\.raw$|([^.]+)\.inc$|([^.]+)\.lck$|([^.]+)\.nz$|([^.]+)\.rc$|([^.]+)\.html\.gz$|([^.]+)\.gz$|([^.]+)\.env$|([^.]+)\.yml$" | httpx -silent -follow-host-redirects | anew -q $resultDir/vulns/files.txt &> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/files.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'sensitive':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/files.json &> /dev/null

    xargs -a $resultDir/tmp/xss.txt -P 50 -I % bash -c "curl -s -L -H \"X-Bugbounty: Testing\" -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\" --insecure '%' | grep \"<svg/onload=confirm(document.domain)>\" && echo -e \"[POTENTIAL XSS] - % \n \"" 2> /dev/null | grep "POTENTIAL XSS" | anew $resultDir/vulns/xss.txt | notify -silent &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/xss.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/xss.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'vuln_xss':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/xss.json &> /dev/null

    xargs -a $resultDir/.gf/ssrf.list -P 50 -I % bash -c "curl -ks -H \"X-Bugbounty: Testing\" -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\" --insecure '%' | grep \"compute.internal\" && echo -e \"[POTENTIAL SSRF] - % \n \"" 2> /dev/null | grep "POTENTIAL SSRF" | anew $resultDir/vulns/ssrf.txt | notify -silent &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/ssrf.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/ssrf.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'vuln_ssrf':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/ssrf.json &> /dev/null

    xargs -a $resultDir/.gf/redirect.list -P 50 -I % bash -c "curl -s -iL -H \"X-Bugbounty: Testing\" -H \"User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36\" --insecure '%' | grep \"Evil.Com - We get it...Daily\" && echo -e \"[POTENTIAL REDIRECT] - % \n \"" 2> /dev/null | grep "POTENTIAL REDIRECT" | anew $resultDir/vulns/redirect.txt | notify -silent &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/redirect.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/redirect.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'vuln_redirect':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/redirect.json &> /dev/null

    timeout 50m xargs -a $resultDir/.gf/sqli.list -P 50 -I % bash -c "echo % | jeeves --payload-time 5" | grep "Vulnerable To" | anew $resultDir/vulns/sqli.txt | notify -silent 2> /dev/null &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/sqli.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/sqli.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'vuln_redirect':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/redirect.json &> /dev/null

    dalfox file $resultDir/tmp/xssp.list --silence --no-color --waf-evasion --no-spinner --mass --mass-worker 100 --skip-bav -w 100 -H "X-Bugbounty: Testing" -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36" 2> /dev/null | anew $resultDir/vulns/dalfoxss.txt | notify -silent &> /dev/null
    [ "$SL" == "False" ] && cat $resultDir/vulns/dalfoxss.txt 2> /dev/null
    [ "$JO" == "False" ] || cat $resultDir/vulns/dalfoxss.txt 2> /dev/null | python3 -c "import sys; import json; print (json.dumps({'dalfox':list(sys.stdin)}))" | sed 's/\\n//g' | tee $resultDir/.json/dalfox.json &> /dev/null

    [ "$JO" == "False" ] || cat $resultDir/.json/*.json | jq -s 'add' 2> /dev/null | tee $resultDir/.json/output.json &> /dev/null
}

#@> DIRECTORY FUZZING
FUZZ_DIRS(){
    echo -e "${BOLD}${LIGHT_MAGENTA}        ${NORMAL}" | tr -d '\n' | pv -qL 6; echo -e " STARTING DIRECTORY FUZZING ON ${BOLD}${LIGHT_MAGENTA}$DM${NORMAL} (${YW}it may take time${NORMAL})"
    for target in $(cat $resultDir/lives.txt); do
        fuzzout=$(echo $target | awk -F// '{print $NF}' | sed -E 's/[\.|:]+/_/g')
        ffuf -u $target/FUZZ -ac -t 100 -mc 200 -sf -H "User-Agent: Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.77 Safari/537.36" -w ~/vasuki/wordlists/fuzz.txt -p '0.6-1.2' -e .html,.json,.php,.asp,.aspx,.log,.sql,.txt,.asp,.jsp,.bak,~,.db -maxtime 900 -o $resultDir/dirs/$fuzzout.json -s 2> /dev/null &> /dev/null
        cat $resultDir/dirs/$fuzzout.json | jq -r '.results[] | .status, .length, .url' 2> /dev/null | xargs -n3 | anew -q $resultDir/dirs/$fuzzout.txt
        rm -rf $resultDir/dirs/$fuzzout.json
    done
}

#@> SENDING FINAL NOTIFICATION
SEND_NOTE(){
    echo -e ""
    echo -e "${BOLD}${LIGHT_MAGENTA} SCANNING COMPLETED SUCCESSFULLY ON $DM ${NORMAL}"
    echo -e "[VASUKI] - Scanning completed on $DM at $(date)" | notify -silent
    ReconEndTime=$(date +%H.%M.%S)
    link=http://$(curl ifconfig.co)/$domain.zip
    echo -e "Results in : ${LIGHT_GREEN}$resultDir${NORMAL}"
    cd $resultDir && zip "/var/www/html/$domain.zip" -r .
    echo -e "${LIGHT_GREEN}" && tree $resultDir && echo -en "${NORMAL}"
    echo -e "Download your zip from : ${BOLD}${LIGHT_GREEN}${UNDERLINE}$link${NORMAL}"
    echo -e "Total Time taken : ${LIGHT_GREEN} $(( $ReconEndTime-$ReconStartTime )) ${NORMAL}seconds"    
}

VAULT(){
    SUBD_SCAN 2> /dev/null
    find_ips 2> /dev/null
    find_ipclean 2> /dev/null
    MASSCAN_IP 2> /dev/null
    nmap_run 2> /dev/null
    WEBC_RAWL 2> /dev/null
    NUCL_SCAN 2> /dev/null
    VULN_SCAN 2> /dev/null
    FUZZ_DIRS 2> /dev/null
    SEND_NOTE 2> /dev/null
}

while true
do
    INFOM
    MAKDR
    VAULT
    exit
done
